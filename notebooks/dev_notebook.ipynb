{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EduPredict Development Notebook\n",
    "\n",
    "This notebook implements the data pipeline refinement and model optimization for the Early Warning Academic Performance Prediction system.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Data Loading and Processing\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Engineering\n",
    "4. Model Development (Random Forest Path)\n",
    "5. Hyperparameter Tuning\n",
    "6. Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Project Modules\n",
    "\n",
    "Import the custom modules developed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# add project root to python path\n",
    "sys.path.append('..')\n",
    "\n",
    "# import custom modules\n",
    "from data_processing import load_raw_datasets, clean_demographic_data, clean_vle_data, clean_assessment_data, validate_data_consistency\n",
    "from eda import perform_automated_eda, analyze_student_performance, analyze_engagement_patterns, document_eda_findings, visualize_demographic_distributions\n",
    "from feature_engineering import create_demographic_features, create_temporal_features, create_assessment_features, create_sequential_features, prepare_dual_path_features, create_stratified_splits, prepare_target_variable\n",
    "from performance_metrics import analyze_feature_importance, analyze_feature_correlations, calculate_model_metrics, calculate_fairness_metrics, plot_roc_curves, plot_fairness_metrics\n",
    "from hyperparameter_tuning import tune_random_forest, visualize_tuning_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Processing\n",
    "\n",
    "Load the OULAD dataset files using memory-optimized strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# set data path\n",
    "data_path = '../data/OULAD/'\n",
    "\n",
    "# check if data exists\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Data not found at: {data_path}\")\n",
    "    print(\"Please create the directory and place the OULAD data files there.\")\n",
    "else:\n",
    "    print(f\"Loading data from: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# load datasets using optimized loading function\n",
    "try:\n",
    "    datasets = load_raw_datasets(data_path)\n",
    "    print(\"\\nDatasets loaded successfully.\")\n",
    "    \n",
    "    # verify data consistency\n",
    "    if validate_data_consistency(datasets):\n",
    "        print(\"Data consistency validation passed.\")\n",
    "    else:\n",
    "        print(\"Data consistency validation failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# display dataset shapes\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Datasets\n",
    "\n",
    "Apply cleaning functions to each dataset component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# clean demographic data\n",
    "clean_demographics = clean_demographic_data(datasets['student_info'])\n",
    "print(f\"Clean demographics shape: {clean_demographics.shape}\")\n",
    "\n",
    "# clean vle data\n",
    "clean_vle = clean_vle_data(datasets['vle_interactions'], datasets['vle_materials'])\n",
    "print(f\"Clean VLE data shape: {clean_vle.shape}\")\n",
    "\n",
    "# clean assessment data\n",
    "clean_assessments = clean_assessment_data(datasets['assessments'], datasets['student_assessments'])\n",
    "print(f\"Clean assessment data shape: {clean_assessments.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Perform automated EDA to understand data characteristics and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# run automated eda on clean datasets\n",
    "clean_datasets = {\n",
    "    'demographics': clean_demographics,\n",
    "    'vle': clean_vle,\n",
    "    'assessments': clean_assessments\n",
    "}\n",
    "\n",
    "# get documented findings\n",
    "eda_findings = document_eda_findings(clean_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# visualize demographic distributions\n",
    "visualize_demographic_distributions(clean_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# examine performance patterns by demographic group\n",
    "# combine demographic and assessment data\n",
    "demo_assessment = clean_demographics.merge(\n",
    "    clean_assessments,\n",
    "    on=['id_student', 'code_module', 'code_presentation'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# analyze performance across demographic groups\n",
    "for col in ['gender', 'age_band', 'imd_band']:\n",
    "    if col in demo_assessment.columns:\n",
    "        print(f\"\\nAverage score by {col}:\")\n",
    "        print(demo_assessment.groupby(col, observed=False)['score'].mean().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# examine final result distribution\n",
    "if 'final_result' in clean_demographics.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    result_counts = clean_demographics['final_result'].value_counts()\n",
    "    result_counts.plot(kind='bar')\n",
    "    plt.title('Distribution of Final Results')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    # add percentage labels\n",
    "    total = result_counts.sum()\n",
    "    for i, count in enumerate(result_counts):\n",
    "        plt.text(i, count + 100, f'{100 * count / total:.1f}%', ha='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create features for both paths of the dual-path architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# create demographic features\n",
    "demographic_features = create_demographic_features(clean_demographics)\n",
    "print(f\"Demographic features shape: {demographic_features.shape}\")\n",
    "\n",
    "# display sample of demographic features\n",
    "demographic_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# create temporal features with multiple window sizes\n",
    "window_sizes = [7, 14, 30]  # weekly, bi-weekly, monthly\n",
    "temporal_features = create_temporal_features(clean_vle, window_sizes)\n",
    "\n",
    "# display info about temporal features\n",
    "for window_size, features in temporal_features.items():\n",
    "    print(f\"{window_size} features shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# create assessment features\n",
    "assessment_features = create_assessment_features(clean_assessments)\n",
    "print(f\"Assessment features shape: {assessment_features.shape}\")\n",
    "\n",
    "# display sample of assessment features\n",
    "assessment_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# create sequential features for gru path\n",
    "sequential_features = create_sequential_features(clean_vle)\n",
    "print(f\"Sequential features shape: {sequential_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# prepare dual path features\n",
    "dual_path_features = prepare_dual_path_features(\n",
    "    demographic_features, \n",
    "    temporal_features,\n",
    "    assessment_features,\n",
    "    sequential_features\n",
    ")\n",
    "\n",
    "# check shapes of dual path features\n",
    "for path_name, features in dual_path_features.items():\n",
    "    print(f\"{path_name} shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Target Variable\n",
    "\n",
    "Create binary target variable: at-risk (1) vs. not-at-risk (0) students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# create binary target variable\n",
    "static_features = dual_path_features['static_path']\n",
    "y = prepare_target_variable(static_features)\n",
    "\n",
    "# check target distribution\n",
    "target_counts = y.value_counts()\n",
    "print(\"Target distribution:\")\n",
    "print(target_counts)\n",
    "print(f\"Percentage at risk: {100 * target_counts.get(1, 0) / len(y):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stratified Train/Test Splits\n",
    "\n",
    "Create train/test splits while preserving demographic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# create stratified splits\n",
    "split_data = create_stratified_splits(dual_path_features, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# prepare data for static path modeling\n",
    "X_train_static = split_data['static_train'].drop(['final_result', 'id_student', 'code_module', 'code_presentation'], axis=1, errors='ignore')\n",
    "X_test_static = split_data['static_test'].drop(['final_result', 'id_student', 'code_module', 'code_presentation'], axis=1, errors='ignore')\n",
    "\n",
    "# prepare target variables\n",
    "y_train = prepare_target_variable(split_data['static_train'])\n",
    "y_test = prepare_target_variable(split_data['static_test'])\n",
    "\n",
    "# display shapes\n",
    "print(f\"X_train shape: {X_train_static.shape}\")\n",
    "print(f\"X_test shape: {X_test_static.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Feature Importance and Correlations\n",
    "\n",
    "Identify important features and check for multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# analyze feature importance\n",
    "feature_importance = analyze_feature_importance(X_train_static, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# identify highly correlated features\n",
    "correlated_features = analyze_feature_correlations(X_train_static, threshold=0.85)\n",
    "\n",
    "if len(correlated_features) > 0:\n",
    "    print(\"\\nHighly correlated features:\")\n",
    "    print(correlated_features)\n",
    "else:\n",
    "    print(\"\\nNo highly correlated features found (threshold: 0.85).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development (Random Forest Path)\n",
    "\n",
    "Implement baseline Random Forest model for the static path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# feature selection based on importance\n",
    "importance_threshold = 0.01\n",
    "important_features = feature_importance[feature_importance['Importance'] > importance_threshold]['Feature'].tolist()\n",
    "print(f\"Selected {len(important_features)} features with importance > {importance_threshold}\")\n",
    "\n",
    "# filter to important features\n",
    "X_train_selected = X_train_static[important_features]\n",
    "X_test_selected = X_test_static[important_features]\n",
    "\n",
    "print(f\"X_train_selected shape: {X_train_selected.shape}\")\n",
    "print(f\"X_test_selected shape: {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# train baseline random forest model\n",
    "baseline_rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "baseline_rf.fit(X_train_selected, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = baseline_rf.predict(X_test_selected)\n",
    "y_prob = baseline_rf.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# display classification report\n",
    "print(\"Classification Report (Baseline Random Forest):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# ROC AUC score\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"\\nROC AUC Score: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning\n",
    "\n",
    "Optimize model hyperparameters for the Random Forest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# define parameter grid for random forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}\n",
    "\n",
    "# tune random forest hyperparameters\n",
    "best_params, best_model = tune_random_forest(\n",
    "    X_train_selected, \n",
    "    y_train,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    random_search=True,\n",
    "    n_iter=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# evaluate optimized model\n",
    "y_pred_opt = best_model.predict(X_test_selected)\n",
    "y_prob_opt = best_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# display classification report\n",
    "print(\"Classification Report (Optimized Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_opt))\n",
    "\n",
    "# display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "print(cm_opt)\n",
    "\n",
    "# ROC AUC score\n",
    "auc_opt = roc_auc_score(y_test, y_prob_opt)\n",
    "print(f\"\\nROC AUC Score: {auc_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# plot ROC curve\n",
    "plot_roc_curves(y_test, y_prob_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fairness Analysis\n",
    "\n",
    "Evaluate model fairness across demographic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# prepare protected attributes for fairness analysis\n",
    "protected_attributes = {}\n",
    "\n",
    "for attr in ['gender', 'age_band', 'imd_band']:\n",
    "    if attr in split_data['static_test'].columns:\n",
    "        protected_attributes[attr] = split_data['static_test'][attr].values\n",
    "\n",
    "# calculate fairness metrics\n",
    "fairness_results = calculate_fairness_metrics(\n",
    "    y_test.values, \n",
    "    y_pred_opt, \n",
    "    y_prob_opt,\n",
    "    protected_attributes\n",
    ")\n",
    "\n",
    "# display fairness metrics\n",
    "for attr, metrics in fairness_results.items():\n",
    "    print(f\"\\nFairness metrics for {attr}:\")\n",
    "    if 'demographic_parity_difference' in metrics:\n",
    "        print(f\"Demographic parity difference: {metrics['demographic_parity_difference']:.4f}\")\n",
    "    if 'disparate_impact_ratio' in metrics:\n",
    "        print(f\"Disparate impact ratio: {metrics['disparate_impact_ratio']:.4f}\")\n",
    "    if 'equal_opportunity_difference' in metrics:\n",
    "        print(f\"Equal opportunity difference: {metrics['equal_opportunity_difference']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# plot fairness metrics by demographic group\n",
    "plot_fairness_metrics(fairness_results, metric_name='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# plot ROC curves by gender\n",
    "if 'gender' in protected_attributes:\n",
    "    plot_roc_curves(y_test.values, y_prob_opt, protected_attributes['gender'], group_name='Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# plot ROC curves by IMD band\n",
    "if 'imd_band' in protected_attributes:\n",
    "    plot_roc_curves(y_test.values, y_prob_opt, protected_attributes['imd_band'], group_name='IMD Band')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Results\n",
    "\n",
    "Save the optimized model and key results for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# save optimized random forest model\n",
    "joblib.dump(best_model, '../models/random_forest_optimized.pkl')\n",
    "print(\"Saved optimized Random Forest model.\")\n",
    "\n",
    "# save important features list\n",
    "pd.Series(important_features).to_csv('../models/important_features.csv', index=False)\n",
    "print(\"Saved important features list.\")\n",
    "\n",
    "# save feature importance data\n",
    "feature_importance.to_csv('../models/feature_importance.csv', index=False)\n",
    "print(\"Saved feature importance data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Implement GRU model for the sequential path\n",
    "2. Optimize GRU hyperparameters using Google Colab\n",
    "3. Integrate ensemble model combining both paths\n",
    "4. Develop Tableau dashboard for visualization\n",
    "5. Implement ConverSight integration for conversational analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
